{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras-Activations.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOLAsiwzISLhTAUhzobUG4P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NehaKoppikar/BTDSS6DL/blob/master/Practical/Practical%206/Keras_Activations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuBZ6OdzoJEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5k_UpEnoc8r",
        "colab_type": "text"
      },
      "source": [
        "# MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLthnUBSoS48",
        "colab_type": "text"
      },
      "source": [
        "## elu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkGiMe_boUFC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7ac557a7-b6d8-40fe-a370-10df61030d17"
      },
      "source": [
        "import keras\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "\n",
        "NUM_ROWS = 28\n",
        "NUM_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "\n",
        "# Load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape data\n",
        "X_train = X_train.reshape((X_train.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Categorically encode labels\n",
        "y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = to_categorical(y_test, NUM_CLASSES)\n",
        "\n",
        "\n",
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='elu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='elu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 0.2924 - acc: 0.9102 - val_loss: 0.1318 - val_acc: 0.9589\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.1261 - acc: 0.9616 - val_loss: 0.0979 - val_acc: 0.9714\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.0853 - acc: 0.9737 - val_loss: 0.0947 - val_acc: 0.9715\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.0662 - acc: 0.9788 - val_loss: 0.0885 - val_acc: 0.9747\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.0523 - acc: 0.9832 - val_loss: 0.0832 - val_acc: 0.9753\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.0411 - acc: 0.9865 - val_loss: 0.0915 - val_acc: 0.9744\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0352 - acc: 0.9887 - val_loss: 0.1008 - val_acc: 0.9735\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.0307 - acc: 0.9898 - val_loss: 0.0999 - val_acc: 0.9753\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.0253 - acc: 0.9919 - val_loss: 0.0866 - val_acc: 0.9787\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.0203 - acc: 0.9936 - val_loss: 0.1023 - val_acc: 0.9782\n",
            "Test loss: 0.10232176107479454\n",
            "Test accuracy: 0.9782\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qViodHpkof_2",
        "colab_type": "text"
      },
      "source": [
        "## softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2d5Eo0Eoe0o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "2e511f97-c836-4d0c-effb-a3ff2970b9e2"
      },
      "source": [
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='softmax', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='softmax'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 2.2687 - acc: 0.2106 - val_loss: 2.1951 - val_acc: 0.4798\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 2.0405 - acc: 0.6505 - val_loss: 1.8520 - val_acc: 0.6759\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 1.6444 - acc: 0.6759 - val_loss: 1.4325 - val_acc: 0.6779\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 1.2516 - acc: 0.6789 - val_loss: 1.0814 - val_acc: 0.6791\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.9606 - acc: 0.6829 - val_loss: 0.8554 - val_acc: 0.6805\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.7930 - acc: 0.6863 - val_loss: 0.7442 - val_acc: 0.6945\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.7154 - acc: 0.6981 - val_loss: 0.6977 - val_acc: 0.6876\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.6807 - acc: 0.7014 - val_loss: 0.6764 - val_acc: 0.6940\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.6622 - acc: 0.7089 - val_loss: 0.6637 - val_acc: 0.7072\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.6482 - acc: 0.7188 - val_loss: 0.6538 - val_acc: 0.7206\n",
            "Test loss: 0.6538230005264283\n",
            "Test accuracy: 0.7206\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCg0wew-onxM",
        "colab_type": "text"
      },
      "source": [
        "## selu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8ipEFheonJ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "660aa474-e33c-4f32-ac2a-a65fb3c9f100"
      },
      "source": [
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='selu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='selu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 8s 138us/step - loss: 0.3399 - acc: 0.8999 - val_loss: 0.1809 - val_acc: 0.9431\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 8s 131us/step - loss: 0.1403 - acc: 0.9574 - val_loss: 0.1124 - val_acc: 0.9655\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 8s 131us/step - loss: 0.0984 - acc: 0.9697 - val_loss: 0.1282 - val_acc: 0.9622\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 8s 133us/step - loss: 0.0747 - acc: 0.9768 - val_loss: 0.1205 - val_acc: 0.9671\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 8s 133us/step - loss: 0.0626 - acc: 0.9805 - val_loss: 0.1184 - val_acc: 0.9655\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 8s 132us/step - loss: 0.0525 - acc: 0.9839 - val_loss: 0.0910 - val_acc: 0.9757\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 8s 137us/step - loss: 0.0458 - acc: 0.9856 - val_loss: 0.0998 - val_acc: 0.9747\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 8s 131us/step - loss: 0.0403 - acc: 0.9875 - val_loss: 0.0917 - val_acc: 0.9777\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 8s 132us/step - loss: 0.0344 - acc: 0.9894 - val_loss: 0.0970 - val_acc: 0.9782\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 8s 132us/step - loss: 0.0306 - acc: 0.9906 - val_loss: 0.1062 - val_acc: 0.9777\n",
            "Test loss: 0.1061582604077401\n",
            "Test accuracy: 0.9777\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzTqN_CzosZo",
        "colab_type": "text"
      },
      "source": [
        "## softplus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2H7ud3uorjZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "e88996c4-3f20-41d3-8170-02bb24c4cc42"
      },
      "source": [
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='softplus', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='softplus'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.4768 - acc: 0.8545 - val_loss: 0.2363 - val_acc: 0.9246\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 8s 126us/step - loss: 0.1793 - acc: 0.9451 - val_loss: 0.1371 - val_acc: 0.9584\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 8s 126us/step - loss: 0.1148 - acc: 0.9645 - val_loss: 0.0929 - val_acc: 0.9704\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0858 - acc: 0.9737 - val_loss: 0.0864 - val_acc: 0.9749\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0661 - acc: 0.9790 - val_loss: 0.0829 - val_acc: 0.9740\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 8s 131us/step - loss: 0.0534 - acc: 0.9832 - val_loss: 0.0751 - val_acc: 0.9783\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 8s 125us/step - loss: 0.0446 - acc: 0.9864 - val_loss: 0.0865 - val_acc: 0.9762\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 124us/step - loss: 0.0380 - acc: 0.9886 - val_loss: 0.0846 - val_acc: 0.9767\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 8s 127us/step - loss: 0.0307 - acc: 0.9902 - val_loss: 0.0926 - val_acc: 0.9767\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 8s 126us/step - loss: 0.0263 - acc: 0.9919 - val_loss: 0.0950 - val_acc: 0.9758\n",
            "Test loss: 0.09501055564472809\n",
            "Test accuracy: 0.9758\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfpXL4PLoymr",
        "colab_type": "text"
      },
      "source": [
        "## softsign"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfxlLwwaox0_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "8da3abc2-6ed8-47c3-a587-1170868f6288"
      },
      "source": [
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='softsign', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='softsign'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 7s 124us/step - loss: 0.2924 - acc: 0.9121 - val_loss: 0.1661 - val_acc: 0.9496\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.1440 - acc: 0.9567 - val_loss: 0.1127 - val_acc: 0.9669\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.0979 - acc: 0.9706 - val_loss: 0.0974 - val_acc: 0.9700\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.0724 - acc: 0.9779 - val_loss: 0.0905 - val_acc: 0.9728\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.0562 - acc: 0.9826 - val_loss: 0.0719 - val_acc: 0.9779\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.0433 - acc: 0.9867 - val_loss: 0.0870 - val_acc: 0.9734\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.0350 - acc: 0.9896 - val_loss: 0.0666 - val_acc: 0.9803\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.0279 - acc: 0.9913 - val_loss: 0.0724 - val_acc: 0.9780\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.0213 - acc: 0.9940 - val_loss: 0.0695 - val_acc: 0.9786\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.0170 - acc: 0.9954 - val_loss: 0.0618 - val_acc: 0.9806\n",
            "Test loss: 0.06178028286402696\n",
            "Test accuracy: 0.9806\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTM_Fksko24Z",
        "colab_type": "text"
      },
      "source": [
        "## relu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EiuTftbo2Vd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "f185d38e-3d0a-460b-eb4a-fb9c67dd76a9"
      },
      "source": [
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.2305 - acc: 0.9288 - val_loss: 0.0916 - val_acc: 0.9709\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0862 - acc: 0.9736 - val_loss: 0.0710 - val_acc: 0.9783\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0567 - acc: 0.9826 - val_loss: 0.0653 - val_acc: 0.9818\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.0408 - acc: 0.9874 - val_loss: 0.0678 - val_acc: 0.9819\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.0294 - acc: 0.9910 - val_loss: 0.0731 - val_acc: 0.9806\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.0229 - acc: 0.9930 - val_loss: 0.0800 - val_acc: 0.9805\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.0198 - acc: 0.9942 - val_loss: 0.0736 - val_acc: 0.9829\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.0145 - acc: 0.9956 - val_loss: 0.0848 - val_acc: 0.9826\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0132 - acc: 0.9958 - val_loss: 0.1168 - val_acc: 0.9783\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.0116 - acc: 0.9965 - val_loss: 0.0945 - val_acc: 0.9817\n",
            "Test loss: 0.09446271277347759\n",
            "Test accuracy: 0.9817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiMoV8rNo9OB",
        "colab_type": "text"
      },
      "source": [
        "## tanh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5snFzh6o8YO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "d83bb704-26a9-4d46-e5a0-7647525f5fb5"
      },
      "source": [
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='tanh', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='tanh'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 8s 125us/step - loss: 0.2917 - acc: 0.9126 - val_loss: 0.1721 - val_acc: 0.9490\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.1243 - acc: 0.9633 - val_loss: 0.1120 - val_acc: 0.9675\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.0814 - acc: 0.9749 - val_loss: 0.0991 - val_acc: 0.9691\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.0586 - acc: 0.9817 - val_loss: 0.0743 - val_acc: 0.9762\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.0429 - acc: 0.9872 - val_loss: 0.0774 - val_acc: 0.9739\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.0321 - acc: 0.9903 - val_loss: 0.0710 - val_acc: 0.9780\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.0233 - acc: 0.9933 - val_loss: 0.0632 - val_acc: 0.9806\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.0171 - acc: 0.9953 - val_loss: 0.0640 - val_acc: 0.9807\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 124us/step - loss: 0.0121 - acc: 0.9968 - val_loss: 0.0780 - val_acc: 0.9765\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.0092 - acc: 0.9976 - val_loss: 0.0700 - val_acc: 0.9808\n",
            "Test loss: 0.06998258561696566\n",
            "Test accuracy: 0.9808\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnZytuuppBj8",
        "colab_type": "text"
      },
      "source": [
        "## sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2O7HcqcupAuT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "a6a08284-0b7b-4039-fff2-e866e95ec389"
      },
      "source": [
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='sigmoid', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='sigmoid'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 8s 126us/step - loss: 0.4927 - acc: 0.8598 - val_loss: 0.2867 - val_acc: 0.9104\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.2152 - acc: 0.9345 - val_loss: 0.1732 - val_acc: 0.9460\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.1546 - acc: 0.9536 - val_loss: 0.1390 - val_acc: 0.9557\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.1163 - acc: 0.9647 - val_loss: 0.1197 - val_acc: 0.9644\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.0912 - acc: 0.9717 - val_loss: 0.0877 - val_acc: 0.9722\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.0741 - acc: 0.9771 - val_loss: 0.0979 - val_acc: 0.9690\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.0609 - acc: 0.9814 - val_loss: 0.0902 - val_acc: 0.9731\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.0515 - acc: 0.9840 - val_loss: 0.0782 - val_acc: 0.9756\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0435 - acc: 0.9868 - val_loss: 0.0720 - val_acc: 0.9785\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.0366 - acc: 0.9886 - val_loss: 0.0930 - val_acc: 0.9720\n",
            "Test loss: 0.09297827541329898\n",
            "Test accuracy: 0.972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7pFXeQepGFP",
        "colab_type": "text"
      },
      "source": [
        "## hard_sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrFsr3AmpFjR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "a1ceaf22-9e20-4694-ce61-b5f39eb9aef2"
      },
      "source": [
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='hard_sigmoid', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='hard_sigmoid'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 8s 136us/step - loss: 0.4998 - acc: 0.8544 - val_loss: 0.2625 - val_acc: 0.9236\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 124us/step - loss: 0.2129 - acc: 0.9365 - val_loss: 0.1792 - val_acc: 0.9462\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 0.1500 - acc: 0.9552 - val_loss: 0.1376 - val_acc: 0.9576\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.1111 - acc: 0.9670 - val_loss: 0.1055 - val_acc: 0.9683\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0868 - acc: 0.9735 - val_loss: 0.0989 - val_acc: 0.9695\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0699 - acc: 0.9786 - val_loss: 0.0894 - val_acc: 0.9733\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 0.0572 - acc: 0.9829 - val_loss: 0.0811 - val_acc: 0.9750\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0465 - acc: 0.9856 - val_loss: 0.0786 - val_acc: 0.9762\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 0.0378 - acc: 0.9884 - val_loss: 0.0830 - val_acc: 0.9755\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 0.0310 - acc: 0.9905 - val_loss: 0.0800 - val_acc: 0.9764\n",
            "Test loss: 0.0800087775741471\n",
            "Test accuracy: 0.9764\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG8BrXKMpLZr",
        "colab_type": "text"
      },
      "source": [
        "## exponential"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6zzcfNUpK4h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "41cac4b5-fb78-4806-dd51-b90ff1acbc42"
      },
      "source": [
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='exponential', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='exponential'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 8s 127us/step - loss: 14.5158 - acc: 0.0992 - val_loss: 14.5385 - val_acc: 0.0980\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 14.5270 - acc: 0.0987 - val_loss: 14.5385 - val_acc: 0.0980\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 14.5270 - acc: 0.0987 - val_loss: 14.5385 - val_acc: 0.0980\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 14.5270 - acc: 0.0987 - val_loss: 14.5385 - val_acc: 0.0980\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 14.5270 - acc: 0.0987 - val_loss: 14.5385 - val_acc: 0.0980\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 114us/step - loss: 14.5270 - acc: 0.0987 - val_loss: 14.5385 - val_acc: 0.0980\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 14.5270 - acc: 0.0987 - val_loss: 14.5385 - val_acc: 0.0980\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 14.5270 - acc: 0.0987 - val_loss: 14.5385 - val_acc: 0.0980\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 14.5270 - acc: 0.0987 - val_loss: 14.5385 - val_acc: 0.0980\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 114us/step - loss: 14.5270 - acc: 0.0987 - val_loss: 14.5385 - val_acc: 0.0980\n",
            "Test loss: 14.538521841430665\n",
            "Test accuracy: 0.098\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Bg92FDNpPlx",
        "colab_type": "text"
      },
      "source": [
        "## linear"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESvLjAx_pPBD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "17e35bdd-9251-40a4-baf8-dfbc48316802"
      },
      "source": [
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='linear', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='linear'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 8s 127us/step - loss: 0.4256 - acc: 0.8776 - val_loss: 0.3801 - val_acc: 0.8880\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 114us/step - loss: 0.3442 - acc: 0.9028 - val_loss: 0.3473 - val_acc: 0.9028\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 114us/step - loss: 0.3219 - acc: 0.9101 - val_loss: 0.3204 - val_acc: 0.9130\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.3106 - acc: 0.9131 - val_loss: 0.2942 - val_acc: 0.9228\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 0.3013 - acc: 0.9158 - val_loss: 0.2946 - val_acc: 0.9181\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.2972 - acc: 0.9163 - val_loss: 0.3058 - val_acc: 0.9163\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.2907 - acc: 0.9194 - val_loss: 0.3010 - val_acc: 0.9185\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.2872 - acc: 0.9196 - val_loss: 0.2941 - val_acc: 0.9192\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 114us/step - loss: 0.2852 - acc: 0.9208 - val_loss: 0.2814 - val_acc: 0.9227\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.2825 - acc: 0.9212 - val_loss: 0.3002 - val_acc: 0.9190\n",
            "Test loss: 0.30019719673097134\n",
            "Test accuracy: 0.919\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXzmsvT-pUAt",
        "colab_type": "text"
      },
      "source": [
        "## LeakyReLU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pr0Cw-YipTeE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "ea210292-6e9c-4564-98bb-c71814f80e77"
      },
      "source": [
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation=keras.layers.LeakyReLU(alpha=0.3), input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation=keras.layers.LeakyReLU(alpha=0.3)))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/activations.py:235: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
            "  identifier=identifier.__class__.__name__))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 8s 138us/step - loss: 0.2640 - acc: 0.9193 - val_loss: 0.1586 - val_acc: 0.9530\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.1250 - acc: 0.9618 - val_loss: 0.1141 - val_acc: 0.9653\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.0927 - acc: 0.9714 - val_loss: 0.1147 - val_acc: 0.9610\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0760 - acc: 0.9763 - val_loss: 0.0944 - val_acc: 0.9716\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0639 - acc: 0.9800 - val_loss: 0.0897 - val_acc: 0.9737\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0563 - acc: 0.9825 - val_loss: 0.0999 - val_acc: 0.9727\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.0497 - acc: 0.9841 - val_loss: 0.0926 - val_acc: 0.9772\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.0419 - acc: 0.9867 - val_loss: 0.0933 - val_acc: 0.9743\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.0382 - acc: 0.9876 - val_loss: 0.0941 - val_acc: 0.9783\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.0353 - acc: 0.9885 - val_loss: 0.0959 - val_acc: 0.9756\n",
            "Test loss: 0.09586584985366717\n",
            "Test accuracy: 0.9756\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pbAVMD0pZIE",
        "colab_type": "text"
      },
      "source": [
        "## PReLU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lwpv7sQpYlb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "6a03a844-139b-4e6d-dd9d-16d12e1b2ef1"
      },
      "source": [
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation=keras.layers.PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=None)\n",
        ", input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation=keras.layers.PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=None)\n",
        "))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/activations.py:235: UserWarning: Do not pass a layer instance (such as PReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
            "  identifier=identifier.__class__.__name__))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 8s 141us/step - loss: 0.2314 - acc: 0.9302 - val_loss: 0.1046 - val_acc: 0.9672\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0843 - acc: 0.9743 - val_loss: 0.0842 - val_acc: 0.9738\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 8s 125us/step - loss: 0.0563 - acc: 0.9830 - val_loss: 0.0907 - val_acc: 0.9742\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 8s 125us/step - loss: 0.0420 - acc: 0.9864 - val_loss: 0.0706 - val_acc: 0.9796\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 124us/step - loss: 0.0304 - acc: 0.9905 - val_loss: 0.0725 - val_acc: 0.9820\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 8s 125us/step - loss: 0.0238 - acc: 0.9923 - val_loss: 0.0929 - val_acc: 0.9757\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 125us/step - loss: 0.0185 - acc: 0.9940 - val_loss: 0.0875 - val_acc: 0.9806\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 125us/step - loss: 0.0159 - acc: 0.9953 - val_loss: 0.0784 - val_acc: 0.9813\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 125us/step - loss: 0.0128 - acc: 0.9959 - val_loss: 0.0941 - val_acc: 0.9827\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 8s 126us/step - loss: 0.0107 - acc: 0.9967 - val_loss: 0.1203 - val_acc: 0.9784\n",
            "Test loss: 0.12033077089810236\n",
            "Test accuracy: 0.9784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_WvhAJ4pjXG",
        "colab_type": "text"
      },
      "source": [
        "## ELU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-U3DaVSpe3z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "9b9fe69c-0bbb-468d-8e2f-fa5e6f79e3de"
      },
      "source": [
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation=keras.layers.ELU(alpha=1.0), input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation=keras.layers.ELU(alpha=1.0)))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/activations.py:235: UserWarning: Do not pass a layer instance (such as ELU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
            "  identifier=identifier.__class__.__name__))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 8s 136us/step - loss: 0.2859 - acc: 0.9122 - val_loss: 0.1870 - val_acc: 0.9418\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.1222 - acc: 0.9626 - val_loss: 0.1333 - val_acc: 0.9575\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.0845 - acc: 0.9739 - val_loss: 0.0864 - val_acc: 0.9727\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0646 - acc: 0.9795 - val_loss: 0.0863 - val_acc: 0.9749\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0522 - acc: 0.9838 - val_loss: 0.0791 - val_acc: 0.9770\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0415 - acc: 0.9867 - val_loss: 0.0963 - val_acc: 0.9747\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.0353 - acc: 0.9884 - val_loss: 0.0964 - val_acc: 0.9766\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0292 - acc: 0.9903 - val_loss: 0.0940 - val_acc: 0.9744\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0252 - acc: 0.9917 - val_loss: 0.0845 - val_acc: 0.9793\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0207 - acc: 0.9932 - val_loss: 0.0927 - val_acc: 0.9787\n",
            "Test loss: 0.09274291082167592\n",
            "Test accuracy: 0.9787\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdbOdBeTryfH",
        "colab_type": "text"
      },
      "source": [
        "## ThresholdedReLU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBQTt8jBrxsV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "58490f31-a456-4f98-d81e-3d54c22acc25"
      },
      "source": [
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation=keras.layers.ThresholdedReLU(theta=1.0), input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation=keras.layers.ThresholdedReLU(theta=1.0)))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/activations.py:235: UserWarning: Do not pass a layer instance (such as ThresholdedReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
            "  identifier=identifier.__class__.__name__))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 8s 139us/step - loss: 0.6256 - acc: 0.7907 - val_loss: 0.2006 - val_acc: 0.9361\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 0.1518 - acc: 0.9549 - val_loss: 0.1164 - val_acc: 0.9649\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.1008 - acc: 0.9689 - val_loss: 0.1171 - val_acc: 0.9650\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 0.0760 - acc: 0.9767 - val_loss: 0.0856 - val_acc: 0.9747\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0612 - acc: 0.9811 - val_loss: 0.0860 - val_acc: 0.9762\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0499 - acc: 0.9844 - val_loss: 0.0761 - val_acc: 0.9773\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 0.0397 - acc: 0.9875 - val_loss: 0.0765 - val_acc: 0.9781\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 0.0338 - acc: 0.9897 - val_loss: 0.0848 - val_acc: 0.9786\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0285 - acc: 0.9912 - val_loss: 0.0784 - val_acc: 0.9788\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0249 - acc: 0.9925 - val_loss: 0.0880 - val_acc: 0.9787\n",
            "Test loss: 0.08803005875899589\n",
            "Test accuracy: 0.9787\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vw3LjnYrr6II",
        "colab_type": "text"
      },
      "source": [
        "## softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7We381yYr5jL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "042a599a-d034-436e-f4b1-9189201bc351"
      },
      "source": [
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation=keras.layers.Softmax(axis=-1), input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation=keras.layers.Softmax(axis=-1)))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/activations.py:235: UserWarning: Do not pass a layer instance (such as Softmax) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
            "  identifier=identifier.__class__.__name__))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 8s 137us/step - loss: 2.2691 - acc: 0.1938 - val_loss: 2.1962 - val_acc: 0.6152\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 8s 127us/step - loss: 2.0405 - acc: 0.7239 - val_loss: 1.8516 - val_acc: 0.7441\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 1.6423 - acc: 0.7490 - val_loss: 1.4285 - val_acc: 0.7504\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 1.2367 - acc: 0.7540 - val_loss: 1.0530 - val_acc: 0.7524\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.9124 - acc: 0.7567 - val_loss: 0.7919 - val_acc: 0.7575\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.7155 - acc: 0.7598 - val_loss: 0.6573 - val_acc: 0.7619\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.6190 - acc: 0.7627 - val_loss: 0.5933 - val_acc: 0.7659\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.5735 - acc: 0.7656 - val_loss: 0.5660 - val_acc: 0.7671\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.5499 - acc: 0.7691 - val_loss: 0.5515 - val_acc: 0.7719\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.5364 - acc: 0.7721 - val_loss: 0.5425 - val_acc: 0.7694\n",
            "Test loss: 0.5424600038528442\n",
            "Test accuracy: 0.7694\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtzPUk3WshC0",
        "colab_type": "text"
      },
      "source": [
        " **Elu performed the best on test data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAkggf5hssSt",
        "colab_type": "text"
      },
      "source": [
        "# CIFAR 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kmE5TxOtqG3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "51740b8c-2aa7-404e-e9a3-fdd1d19a69bf"
      },
      "source": [
        "import keras\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout, Conv2D,Flatten\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "\n",
        "#Load data\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "#change shape from image to vector\n",
        "X_train = X_train.reshape(50000,32,32,3)\n",
        "X_test = X_test.reshape(10000,32,32,3)\n",
        "\n",
        "#preprocess\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "#change labels from numeric to one hot encoded\n",
        "Y_train = to_categorical(y_train, 10)\n",
        "Y_test =  to_categorical(y_test, 10)\n",
        "\n",
        "adamax=keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Conv2D(1024, (32, 32), padding=\"valid\", activation=keras.layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0), input_shape=X_train.shape[1:]))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation=keras.layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0)\n",
        ", input_shape=(32 * 32,)))\n",
        "model.add(Dense(256, activation=keras.layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0)\n",
        "))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adamax',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=128,\n",
        "          epochs=10,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, Y_test))\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/activations.py:235: UserWarning: Do not pass a layer instance (such as ReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
            "  identifier=identifier.__class__.__name__))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 1.9530 - acc: 0.3001 - val_loss: 1.7458 - val_acc: 0.3808\n",
            "Epoch 2/10\n",
            "50000/50000 [==============================] - 122s 2ms/step - loss: 1.6984 - acc: 0.3939 - val_loss: 1.6713 - val_acc: 0.3994\n",
            "Epoch 3/10\n",
            "50000/50000 [==============================] - 121s 2ms/step - loss: 1.6049 - acc: 0.4274 - val_loss: 1.5927 - val_acc: 0.4385\n",
            "Epoch 4/10\n",
            "50000/50000 [==============================] - 121s 2ms/step - loss: 1.5404 - acc: 0.4494 - val_loss: 1.5589 - val_acc: 0.4427\n",
            "Epoch 5/10\n",
            "50000/50000 [==============================] - 119s 2ms/step - loss: 1.4915 - acc: 0.4666 - val_loss: 1.5158 - val_acc: 0.4603\n",
            "Epoch 6/10\n",
            "50000/50000 [==============================] - 121s 2ms/step - loss: 1.4443 - acc: 0.4860 - val_loss: 1.5136 - val_acc: 0.4638\n",
            "Epoch 7/10\n",
            "50000/50000 [==============================] - 120s 2ms/step - loss: 1.4074 - acc: 0.4992 - val_loss: 1.4469 - val_acc: 0.4798\n",
            "Epoch 8/10\n",
            "50000/50000 [==============================] - 119s 2ms/step - loss: 1.3705 - acc: 0.5112 - val_loss: 1.4188 - val_acc: 0.4896\n",
            "Epoch 9/10\n",
            "50000/50000 [==============================] - 119s 2ms/step - loss: 1.3340 - acc: 0.5246 - val_loss: 1.3735 - val_acc: 0.5155\n",
            "Epoch 10/10\n",
            "50000/50000 [==============================] - 119s 2ms/step - loss: 1.3022 - acc: 0.5338 - val_loss: 1.4220 - val_acc: 0.4973\n",
            "Test loss: 1.4220323947906495\n",
            "Test accuracy: 0.4973\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDxlTR-OtRDs",
        "colab_type": "text"
      },
      "source": [
        "## CIFAR 100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHzahYoWtJYO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "c838ad12-67a1-43c4-e558-240c774211ea"
      },
      "source": [
        "import keras\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout, Conv2D,Flatten\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import cifar100\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "\n",
        "#Load data\n",
        "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
        "\n",
        "#change shape from image to vector\n",
        "X_train = X_train.reshape(50000,32,32,3)\n",
        "X_test = X_test.reshape(10000,32,32,3)\n",
        "\n",
        "#preprocess\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "#change labels from numeric to one hot encoded\n",
        "Y_train = to_categorical(y_train, 100)\n",
        "Y_test =  to_categorical(y_test, 100)\n",
        "\n",
        "adamax=keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Conv2D(1024, (32, 32), padding=\"valid\", activation=keras.layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0), input_shape=X_train.shape[1:]))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation=keras.layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0)\n",
        ", input_shape=(32 * 32,)))\n",
        "model.add(Dense(256, activation=keras.layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0)\n",
        "))\n",
        "model.add(Dense(100, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adamax',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=128,\n",
        "          epochs=10,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, Y_test))\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/activations.py:235: UserWarning: Do not pass a layer instance (such as ReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
            "  identifier=identifier.__class__.__name__))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "50000/50000 [==============================] - 110s 2ms/step - loss: 4.2698 - acc: 0.0562 - val_loss: 3.9695 - val_acc: 0.0899\n",
            "Epoch 2/10\n",
            "50000/50000 [==============================] - 113s 2ms/step - loss: 3.8129 - acc: 0.1168 - val_loss: 3.7151 - val_acc: 0.1346\n",
            "Epoch 3/10\n",
            "50000/50000 [==============================] - 116s 2ms/step - loss: 3.6202 - acc: 0.1504 - val_loss: 3.5978 - val_acc: 0.1573\n",
            "Epoch 4/10\n",
            "50000/50000 [==============================] - 121s 2ms/step - loss: 3.4827 - acc: 0.1728 - val_loss: 3.4632 - val_acc: 0.1891\n",
            "Epoch 5/10\n",
            "50000/50000 [==============================] - 117s 2ms/step - loss: 3.3665 - acc: 0.1966 - val_loss: 3.3923 - val_acc: 0.1966\n",
            "Epoch 6/10\n",
            "50000/50000 [==============================] - 116s 2ms/step - loss: 3.2708 - acc: 0.2122 - val_loss: 3.3304 - val_acc: 0.2133\n",
            "Epoch 7/10\n",
            "50000/50000 [==============================] - 114s 2ms/step - loss: 3.1842 - acc: 0.2283 - val_loss: 3.3067 - val_acc: 0.2115\n",
            "Epoch 8/10\n",
            "50000/50000 [==============================] - 112s 2ms/step - loss: 3.1137 - acc: 0.2408 - val_loss: 3.2585 - val_acc: 0.2221\n",
            "Epoch 9/10\n",
            "50000/50000 [==============================] - 112s 2ms/step - loss: 3.0364 - acc: 0.2553 - val_loss: 3.2571 - val_acc: 0.2246\n",
            "Epoch 10/10\n",
            "50000/50000 [==============================] - 111s 2ms/step - loss: 2.9648 - acc: 0.2693 - val_loss: 3.2480 - val_acc: 0.2296\n",
            "Test loss: 3.247971137237549\n",
            "Test accuracy: 0.2296\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ng-ohLqJtwWj",
        "colab_type": "text"
      },
      "source": [
        "# Fashion MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I2TTczEtvdn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "outputId": "68b55aa8-a617-4720-8b6e-fd36f58c4ded"
      },
      "source": [
        "import keras\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "from keras.layers import Activation, Flatten, Conv2D\n",
        "\n",
        "NUM_ROWS = 28\n",
        "NUM_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "\n",
        "# Load data\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Reshape data\n",
        "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "\n",
        "\n",
        "# Categorically encode labels\n",
        "y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = to_categorical(y_test, NUM_CLASSES)\n",
        "\n",
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Conv2D(512, (28, 28), padding=\"valid\", activation=keras.layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0), input_shape=X_train.shape[1:]))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation=keras.layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0)\n",
        ", input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation=keras.layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0)\n",
        "))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 3us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/activations.py:235: UserWarning: Do not pass a layer instance (such as ReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
            "  identifier=identifier.__class__.__name__))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 13s 211us/step - loss: 0.6001 - acc: 0.7765 - val_loss: 0.4690 - val_acc: 0.8267\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 13s 212us/step - loss: 0.3999 - acc: 0.8533 - val_loss: 0.4137 - val_acc: 0.8552\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 12s 205us/step - loss: 0.3527 - acc: 0.8696 - val_loss: 0.4290 - val_acc: 0.8486\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 12s 204us/step - loss: 0.3322 - acc: 0.8785 - val_loss: 0.3775 - val_acc: 0.8685\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 12s 205us/step - loss: 0.3138 - acc: 0.8844 - val_loss: 0.3853 - val_acc: 0.8594\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 12s 204us/step - loss: 0.3051 - acc: 0.8875 - val_loss: 0.4082 - val_acc: 0.8583\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 13s 209us/step - loss: 0.2934 - acc: 0.8922 - val_loss: 0.3955 - val_acc: 0.8721\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 12s 206us/step - loss: 0.2867 - acc: 0.8947 - val_loss: 0.3649 - val_acc: 0.8801\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 12s 206us/step - loss: 0.2808 - acc: 0.8986 - val_loss: 0.3845 - val_acc: 0.8736\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 12s 205us/step - loss: 0.2732 - acc: 0.9010 - val_loss: 0.3702 - val_acc: 0.8830\n",
            "Test loss: 0.37023280481100085\n",
            "Test accuracy: 0.883\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q32IpI1JuDDQ",
        "colab_type": "text"
      },
      "source": [
        "# Iris"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpvJgfxsuD9h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "6c2d430a-df3a-40c0-c2a5-62237071fd8f"
      },
      "source": [
        "import keras\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.datasets import load_iris\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "from keras.layers import Activation, Flatten, Conv2D\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "\n",
        "# Load data\n",
        "iris_data = load_iris()\n",
        "\n",
        "x = iris_data.data\n",
        "y = iris_data.target.reshape(-1, 1) # Convert data to a single column\n",
        "X_train, X_test, y_train, y_test = tts(x,y,test_size=0.3, random_state=42) \n",
        "\n",
        "\n",
        "# Categorically encode labels\n",
        "y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = to_categorical(y_test, NUM_CLASSES)\n",
        "\n",
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "#model.add(Conv2D(10, (28, 28), padding=\"valid\", activation=keras.layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0), input_shape=X_train.shape[1:]))\n",
        "#model.add(Flatten())\n",
        "model.add(Dense(10, activation=keras.layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0)\n",
        ", input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(10, activation=keras.layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0)\n",
        "))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/activations.py:235: UserWarning: Do not pass a layer instance (such as ReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
            "  identifier=identifier.__class__.__name__))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-59d0dbc0b931>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m           validation_data=(X_test, y_test))\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    139\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_10_input to have shape (784,) but got array with shape (4,)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0woSc5t319Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}